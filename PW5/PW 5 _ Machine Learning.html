<!DOCTYPE html>
<!-- saved from url=(0044)https://www.mghassany.com/MLcourse/pw-5.html -->
<html lang="" xml:lang="" class="js-focus-visible" data-js-focus-visible=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>PW 5 | Machine Learning</title>
  <meta name="description" content="PW 5 | Machine Learning course">
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7">

  <meta property="og:title" content="PW 5 | Machine Learning">
  <meta property="og:type" content="book">
  
  
  <meta property="og:description" content="PW 5 | Machine Learning course">
  

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="PW 5 | Machine Learning">
  
  <meta name="twitter:description" content="PW 5 | Machine Learning course">
  

<meta name="author" content="Mohamad Ghassany">


<meta name="date" content="2020-11-28">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html">
<link rel="next" href="https://www.mghassany.com/MLcourse/principal-components-analysis.html">
<script type="text/javascript" async="" src="./PW 5 _ Machine Learning_files/analytics.js.download"></script><script src="./PW 5 _ Machine Learning_files/jquery.min.js.download"></script>
<link href="./PW 5 _ Machine Learning_files/style.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-table.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-bookdown.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-highlight.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-search.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-fontsettings.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/plugin-clipboard.css" rel="stylesheet">









<link href="./PW 5 _ Machine Learning_files/anchor-sections.css" rel="stylesheet">
<script src="./PW 5 _ Machine Learning_files/anchor-sections.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/kePrint.js.download"></script>
<link href="./PW 5 _ Machine Learning_files/fontawesome-all.min.css" rel="stylesheet">
<link href="./PW 5 _ Machine Learning_files/vembedr.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="./PW 5 _ Machine Learning_files/js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-88489172-1');
</script>
<script async="" defer="" src="./PW 5 _ Machine Learning_files/embed.js.download"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="./PW 5 _ Machine Learning_files/style(1).css" type="text/css">
<script type="text/javascript" src="./PW 5 _ Machine Learning_files/MathJax.js.download"></script><link rel="sidebar" href="https://hypothes.is/app.html" type="application/annotator+html" data-hypothesis-asset=""><link rel="notebook" href="https://hypothes.is/notebook" type="application/annotator+html" data-hypothesis-asset=""><link rel="hypothesis-client" href="https://cdn.hypothes.is/hypothesis/1.625.0/build/boot.js" type="application/annotator+javascript" data-hypothesis-asset=""><script type="text/javascript" src="./PW 5 _ Machine Learning_files/annotator.bundle.js.download" data-hypothesis-asset=""></script><link rel="stylesheet" type="text/css" href="./PW 5 _ Machine Learning_files/annotator.css" data-hypothesis-asset=""><link rel="stylesheet" type="text/css" href="./PW 5 _ Machine Learning_files/pdfjs-overrides.css" data-hypothesis-asset=""><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-chartest {display: block; visibility: hidden; position: absolute; top: 0; line-height: normal; font-size: 500%}
.mjx-chartest .mjx-char {display: inline}
.mjx-chartest .mjx-box {padding-top: 1000px}
.MJXc-processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MJXc-processed {display: none}
.mjx-test {display: block; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.mjx-ex-box-test {position: absolute; overflow: hidden; width: 1px; height: 60ex}
.mjx-line-box-test {display: table!important}
.mjx-line-box-test span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
#MathJax_CHTML_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.mjx-chtml .mjx-noError {line-height: 1.2; vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
.MJXc-TeX-unknown-R {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: STIXGeneral,'Cambria Math','Arial Unicode MS',serif; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://mathjax.rstudio.com/latest/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head>

<body class="hypothesis-highlights-always-on"><div id="MathJax_Message" style="display: none;"></div>



  <div class="book without-animation with-summary   font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary"><div class="book-search" role="search"><label for="search-box" aria-hidden="false" hidden="hidden">Type to search</label><input id="search-box" type="search" class="form-control" placeholder="Type to search (Enter for navigation)" title="Use Enter or the &lt;Down&gt; key to navigate to the next match, or the &lt;Up&gt; key to the previous match"></div>
      <nav role="navigation">

<ul class="summary">
<li class="beforeimg">            
   <a href="https://www.esilv.fr/">
       <img src="./PW 5 _ Machine Learning_files/Logo_ESILV_new.png" style="width:75%; padding:0px 0; display:block; margin: 0 auto;" alt="ESILV logo">
    </a>
</li>
<li class="before"><a href="https://www.mghassany.com/MLcourse/">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="https://www.mghassany.com/MLcourse/index.html"><i class="fa fa-check"></i>Welcome</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="index.html"><a href="https://www.mghassany.com/MLcourse/index.html#course-overview"><i class="fa fa-check"></i>Course Overview</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="https://www.mghassany.com/MLcourse/index.html#course-schedule"><i class="fa fa-check"></i>Course Schedule</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="https://www.mghassany.com/MLcourse/introduction.html"><i class="fa fa-check"></i>Introduction</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="introduction.html"><a href="https://www.mghassany.com/MLcourse/introduction.html#what-is-machine-learning"><i class="fa fa-check"></i>What is Machine Learning ?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="https://www.mghassany.com/MLcourse/introduction.html#supervised-learning"><i class="fa fa-check"></i>Supervised Learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="https://www.mghassany.com/MLcourse/introduction.html#unsupervised-learning"><i class="fa fa-check"></i>Unsupervised Learning</a></li>
</ul></li>
<li class="part"><span><b>I Supervised Learning</b></span></li>
<li class="part"><span><b>Regression</b></span></li>
<li class="chapter" data-level="1" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html"><i class="fa fa-check"></i><b>1</b> Linear Regression</a><ul style="display: none;">
<li class="chapter" data-level="1.1" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#notation"><i class="fa fa-check"></i><b>1.1</b> Notation</a></li>
<li class="chapter" data-level="1.2" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#model-representation"><i class="fa fa-check"></i><b>1.2</b> Model Representation</a></li>
<li class="chapter" data-level="1.3" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#why-estimate-f"><i class="fa fa-check"></i><b>1.3</b> Why Estimate <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-1-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-1" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-2" class="mjx-mrow"><span id="MJXc-Node-3" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.491em; padding-right: 0.06em;">f</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi></math></span></span><script type="math/tex" id="MathJax-Element-1">f</script></span> ?</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#prediction"><i class="fa fa-check"></i>Prediction</a></li>
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#inference"><i class="fa fa-check"></i>Inference</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>1.4</b> Simple Linear Regression Model</a></li>
<li class="chapter" data-level="1.5" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#estimating-the-coefficients"><i class="fa fa-check"></i><b>1.5</b> Estimating the Coefficients</a></li>
<li class="chapter" data-level="1.6" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#assessing-the-accuracy-of-the-coefficient-estimates"><i class="fa fa-check"></i><b>1.6</b> Assessing the Accuracy of the Coefficient Estimates</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#hypothesis-testing"><i class="fa fa-check"></i>Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#anova-and-model-fit"><i class="fa fa-check"></i><b>1.7</b> ANOVA and model fit</a><ul style="display: none;">
<li class="chapter" data-level="1.7.1" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#anova"><i class="fa fa-check"></i><b>1.7.1</b> ANOVA</a></li>
<li class="chapter" data-level="1.7.2" data-path="linear-regression.html"><a href="https://www.mghassany.com/MLcourse/linear-regression.html#the-r2-statistic"><i class="fa fa-check"></i><b>1.7.2</b> The <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-2-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-4" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-5" class="mjx-mrow"><span id="MJXc-Node-6" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-7" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">R</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-8" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">2</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>R</mi><mn>2</mn></msup></math></span></span><script type="math/tex" id="MathJax-Element-2">R^2</script></span> Statistic</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html"><i class="fa fa-check"></i>Practical Work 1</a><ul style="display: none;">
<li class="chapter" data-level="1.8" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#some-basics"><i class="fa fa-check"></i><b>1.8</b> Some <svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 581 512"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> basics</a><ul style="display: none;">
<li class="chapter" data-level="1.8.1" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#basic-commands"><i class="fa fa-check"></i><b>1.8.1</b> Basic Commands</a></li>
<li class="chapter" data-level="1.8.2" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#vectors"><i class="fa fa-check"></i><b>1.8.2</b> Vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#matrices-data-frames-and-lists"><i class="fa fa-check"></i><b>1.8.3</b> Matrices, data frames and lists</a></li>
<li class="chapter" data-level="1.8.4" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#graphics"><i class="fa fa-check"></i><b>1.8.4</b> Graphics</a></li>
<li class="chapter" data-level="1.8.5" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#distributions"><i class="fa fa-check"></i><b>1.8.5</b> Distributions</a></li>
<li class="chapter" data-level="1.8.6" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#working-directory"><i class="fa fa-check"></i><b>1.8.6</b> Working directory</a></li>
<li class="chapter" data-level="1.8.7" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#loading-data"><i class="fa fa-check"></i><b>1.8.7</b> Loading Data</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#regression"><i class="fa fa-check"></i><b>1.9</b> Regression</a><ul style="display: none;">
<li class="chapter" data-level="1.9.1" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#the-lm-function"><i class="fa fa-check"></i><b>1.9.1</b> The <code>lm</code> function</a></li>
<li class="chapter" data-level="1.9.2" data-path="practical-work-1.html"><a href="https://www.mghassany.com/MLcourse/practical-work-1.html#boston"><i class="fa fa-check"></i><b>1.9.2</b> Predicting House Value: Boston dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Multiple Linear Regression</a><ul style="display: none;">
<li class="chapter" data-level="2.1" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#the-model"><i class="fa fa-check"></i><b>2.1</b> The Model</a></li>
<li class="chapter" data-level="2.2" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#estimating-the-regression-coefficients"><i class="fa fa-check"></i><b>2.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="2.3" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#some-important-questions"><i class="fa fa-check"></i><b>2.3</b> Some important questions</a><ul style="display: none;">
<li class="chapter" data-level="2.3.1" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#other-consid"><i class="fa fa-check"></i><b>2.3.1</b> Other Considerations in Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#how-to-select-the-best-performing-model"><i class="fa fa-check"></i><b>2.4</b> How to select the best performing model</a><ul style="display: none;">
<li><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#use-the-adjusted-r_adj2-for-multivariate-models">Use the Adjusted <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-3-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msubsup&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msubsup&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-9" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-10" class="mjx-mrow"><span id="MJXc-Node-11" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-12" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">R</span></span></span><span class="mjx-stack" style="vertical-align: -0.335em;"><span class="mjx-sup" style="font-size: 70.7%; padding-bottom: 0.255em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-18" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">2</span></span></span><span class="mjx-sub" style="font-size: 70.7%; padding-right: 0.071em;"><span id="MJXc-Node-13" class="mjx-texatom" style=""><span id="MJXc-Node-14" class="mjx-mrow"><span id="MJXc-Node-15" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.247em; padding-bottom: 0.308em;">a</span></span><span id="MJXc-Node-16" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em; padding-right: 0.003em;">d</span></span><span id="MJXc-Node-17" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.43em; padding-bottom: 0.491em;">j</span></span></span></span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msubsup><mi>R</mi><mrow class="MJX-TeXAtom-ORD"><mi>a</mi><mi>d</mi><mi>j</mi></mrow><mn>2</mn></msubsup></math></span></span><script type="math/tex" id="MathJax-Element-3">R_{adj}^2</script></span> for multivariate models</a></li>
<li class="chapter" data-level="" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#have-a-look-at-the-residuals-or-error-terms"><i class="fa fa-check"></i>Have a look at the residuals or error terms</a></li>
<li class="chapter" data-level="" data-path="multiple-linear-regression.html"><a href="https://www.mghassany.com/MLcourse/multiple-linear-regression.html#histogram-of-residuals"><i class="fa fa-check"></i>Histogram of residuals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-2.html"><a href="https://www.mghassany.com/MLcourse/pw-2.html"><i class="fa fa-check"></i>PW 2</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-2.html"><a href="https://www.mghassany.com/MLcourse/pw-2.html#multiple-linear-regression-1"><i class="fa fa-check"></i>Multiple Linear Regression</a></li>
<li class="chapter" data-level="" data-path="pw-2.html"><a href="https://www.mghassany.com/MLcourse/pw-2.html#reporting"><i class="fa fa-check"></i>Reporting</a></li>
</ul></li>
<li class="part"><span><b>Classification</b></span></li>
<li class="chapter" data-level="3" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html"><i class="fa fa-check"></i><b>3</b> Logistic Regression</a><ul style="display: none;">
<li class="chapter" data-level="3.1" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#logistic-regression-1"><i class="fa fa-check"></i><b>3.2</b> Logistic Regression</a><ul style="display: none;">
<li class="chapter" data-level="3.2.1" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#the-logistic-model"><i class="fa fa-check"></i><b>3.2.1</b> The Logistic Model</a></li>
<li class="chapter" data-level="3.2.2" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#estimating-the-regression-coefficients-1"><i class="fa fa-check"></i><b>3.2.2</b> Estimating the Regression Coefficients</a></li>
<li class="chapter" data-level="3.2.3" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#prediction-1"><i class="fa fa-check"></i><b>3.2.3</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>3.3</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="3.4" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#logreg-examps"><i class="fa fa-check"></i><b>3.4</b> Example</a><ul style="display: none;">
<li class="chapter" data-level="3.4.1" data-path="logistic-regression.html"><a href="https://www.mghassany.com/MLcourse/logistic-regression.html#logreg-examps-challenger"><i class="fa fa-check"></i><b>3.4.1</b> Case study: <em>The Challenger disaster</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-3.html"><a href="https://www.mghassany.com/MLcourse/pw-3.html"><i class="fa fa-check"></i>PW 3</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-3.html"><a href="https://www.mghassany.com/MLcourse/pw-3.html#social-networks-ads"><i class="fa fa-check"></i>Social Networks Ads</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html"><i class="fa fa-check"></i><b>4</b> Discriminant Analysis</a><ul style="display: none;">
<li class="chapter" data-level="4.1" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#introduction-2"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#bayes-theorem"><i class="fa fa-check"></i><b>4.2</b> Bayes Theorem</a></li>
<li class="chapter" data-level="4.3" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#lda-for-p1"><i class="fa fa-check"></i><b>4.3</b> LDA for <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-4-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-19" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-20" class="mjx-mrow"><span id="MJXc-Node-21" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.247em; padding-bottom: 0.491em;">p</span></span><span id="MJXc-Node-22" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.064em; padding-bottom: 0.308em;">=</span></span><span id="MJXc-Node-23" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">1</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>=</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-4">p=1</script></span></a></li>
<li class="chapter" data-level="4.4" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#estimating-the-parameters"><i class="fa fa-check"></i><b>4.4</b> Estimating the parameters</a></li>
<li class="chapter" data-level="4.5" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#lda-for-p-1"><i class="fa fa-check"></i><b>4.5</b> LDA for <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-5-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;&amp;gt;&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-24" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-25" class="mjx-mrow"><span id="MJXc-Node-26" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.247em; padding-bottom: 0.491em;">p</span></span><span id="MJXc-Node-27" class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.247em; padding-bottom: 0.369em;">&gt;</span></span><span id="MJXc-Node-28" class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">1</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mo>&gt;</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-5">p > 1</script></span></a></li>
<li class="chapter" data-level="4.6" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#making-predictions"><i class="fa fa-check"></i><b>4.6</b> Making predictions</a></li>
<li class="chapter" data-level="4.7" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#other-forms-of-discriminant-analysis"><i class="fa fa-check"></i><b>4.7</b> Other forms of Discriminant Analysis</a><ul style="display: none;">
<li class="chapter" data-level="4.7.1" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#quadratic-discriminant-analysis-qda"><i class="fa fa-check"></i><b>4.7.1</b> Quadratic Discriminant Analysis (QDA)</a></li>
<li class="chapter" data-level="4.7.2" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>4.7.2</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="discriminant-analysis.html"><a href="https://www.mghassany.com/MLcourse/discriminant-analysis.html#lda-vs-logistic-regression"><i class="fa fa-check"></i><b>4.8</b> LDA vs Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html"><i class="fa fa-check"></i>PW 4</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#logistic-regression-2"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#decision-boundary-of-logistic-regression"><i class="fa fa-check"></i>Decision Boundary of Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i>Linear Discriminant Analysis (LDA)</a></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#lda-from-scratch"><i class="fa fa-check"></i>LDA from scratch</a></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#quadratic-discriminant-analysis-qda-1"><i class="fa fa-check"></i>Quadratic Discriminant Analysis (QDA)</a></li>
<li class="chapter" data-level="" data-path="pw-4.html"><a href="https://www.mghassany.com/MLcourse/pw-4.html#comparison"><i class="fa fa-check"></i>Comparison</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html"><i class="fa fa-check"></i><b>5</b> Decision Trees &amp; Random Forests</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#the-basics-of-decision-trees"><i class="fa fa-check"></i>The Basics of Decision Trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#classification-trees"><i class="fa fa-check"></i>Classification Trees</a></li>
<li class="chapter" data-level="" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#bagging-random-forests"><i class="fa fa-check"></i>Bagging &amp; Random Forests</a></li>
<li class="chapter" data-level="" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#boosting"><i class="fa fa-check"></i>Boosting</a></li>
<li><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#trees-in-r">Trees in <code>R</code></a></li>
<li class="chapter" data-level="" data-path="decision-trees-random-forests.html"><a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html#random-forests---the-first-choice-method-for-every-data-analysis"><i class="fa fa-check"></i>Random forests - the first-choice method for every data analysis?</a></li>
</ul></li>
<li class="chapter active" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html"><i class="fa fa-check"></i>PW 5</a><ul style="display: block;">
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#regression-trees"><i class="fa fa-check"></i>Regression Trees</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#single-tree"><i class="fa fa-check"></i>Single tree</a></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#bagging"><i class="fa fa-check"></i>Bagging</a></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#random-forests"><i class="fa fa-check"></i>Random Forests</a></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#boosting-1"><i class="fa fa-check"></i>Boosting</a></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#comparison-1"><i class="fa fa-check"></i>Comparison</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#classification-trees-1"><i class="fa fa-check"></i>Classification Trees</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#the-spam-dataset"><i class="fa fa-check"></i>The Spam dataset</a></li>
<li class="chapter" data-level="" data-path="pw-5.html"><a href="https://www.mghassany.com/MLcourse/pw-5.html#extra-tuning"><i class="fa fa-check"></i>Extra: Tuning</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Dimensionality Reduction</b></span></li>
<li class="chapter" data-level="6" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html"><i class="fa fa-check"></i><b>6</b> Principal Components Analysis</a><ul style="display: none;">
<li class="chapter" data-level="6.1" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#principal-components"><i class="fa fa-check"></i><b>6.2</b> Principal Components</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#notations-and-procedure"><i class="fa fa-check"></i>Notations and Procedure</a></li>
<li><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#first-principal-component-textpc_1-y_1">First Principal Component (<span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-6-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mtext&gt;PC&lt;/mtext&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-29" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-30" class="mjx-mrow"><span id="MJXc-Node-31" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-32" class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.43em; padding-bottom: 0.369em;">PC</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-33" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">1</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>PC</mtext><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-6">\text{PC}_1</script></span>): <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-7-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-34" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-35" class="mjx-mrow"><span id="MJXc-Node-36" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.182em;"><span id="MJXc-Node-37" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.247em; padding-right: 0.182em;">Y</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-38" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">1</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Y</mi><mn>1</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-7">Y_1</script></span></a></li>
<li><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#second-principal-component-textpc_2-y_2">Second Principal Component (<span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-8-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mtext&gt;PC&lt;/mtext&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-39" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-40" class="mjx-mrow"><span id="MJXc-Node-41" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-42" class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.43em; padding-bottom: 0.369em;">PC</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-43" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">2</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>PC</mtext><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-8">\text{PC}_2</script></span>): <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-9-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-44" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-45" class="mjx-mrow"><span id="MJXc-Node-46" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.182em;"><span id="MJXc-Node-47" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.247em; padding-right: 0.182em;">Y</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-48" class="mjx-mn" style=""><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.369em; padding-bottom: 0.369em;">2</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Y</mi><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-9">Y_2</script></span></a></li>
<li><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#ith-principal-component-textpc_i-y_i"><span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-10-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msup&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;h&lt;/mi&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-49" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-50" class="mjx-mrow"><span id="MJXc-Node-51" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-52" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.43em; padding-bottom: 0.308em;">i</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span id="MJXc-Node-53" class="mjx-texatom" style=""><span id="MJXc-Node-54" class="mjx-mrow"><span id="MJXc-Node-55" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.43em; padding-bottom: 0.308em;">t</span></span><span id="MJXc-Node-56" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">h</span></span></span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>i</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>h</mi></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-10">i^{th}</script></span> Principal Component (<span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-11-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mtext&gt;PC&lt;/mtext&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-57" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-58" class="mjx-mrow"><span id="MJXc-Node-59" class="mjx-msubsup"><span class="mjx-base"><span id="MJXc-Node-60" class="mjx-mtext"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.43em; padding-bottom: 0.369em;">PC</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-61" class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.43em; padding-bottom: 0.308em;">i</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mtext>PC</mtext><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-11">\text{PC}_i</script></span>): <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-12-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msub&gt;&lt;mi&gt;Y&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-62" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-63" class="mjx-mrow"><span id="MJXc-Node-64" class="mjx-msubsup"><span class="mjx-base" style="margin-right: -0.182em;"><span id="MJXc-Node-65" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.247em; padding-right: 0.182em;">Y</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span id="MJXc-Node-66" class="mjx-mi" style=""><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.43em; padding-bottom: 0.308em;">i</span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>Y</mi><mi>i</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-12">Y_i</script></span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#how-do-we-find-the-coefficients"><i class="fa fa-check"></i><b>6.3</b> How do we find the coefficients?</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#why-it-may-be-possible-to-reduce-dimensions"><i class="fa fa-check"></i>Why It May Be Possible to Reduce Dimensions</a></li>
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#procedure"><i class="fa fa-check"></i>Procedure</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#standardization-of-the-features"><i class="fa fa-check"></i><b>6.4</b> Standardization of the features</a></li>
<li class="chapter" data-level="6.5" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#projection-of-the-data"><i class="fa fa-check"></i><b>6.5</b> Projection of the data</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#scores"><i class="fa fa-check"></i>Scores</a></li>
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#visualization"><i class="fa fa-check"></i>Visualization</a></li>
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#extra"><i class="fa fa-check"></i>Extra</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#case-study"><i class="fa fa-check"></i><b>6.6</b> Case study</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="principal-components-analysis.html"><a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html#employement-in-european-countries-in-the-late-70s"><i class="fa fa-check"></i>Employement in European countries in the late 70s</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-6.html"><a href="https://www.mghassany.com/MLcourse/pw-6.html"><i class="fa fa-check"></i>PW 6</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-6.html"><a href="https://www.mghassany.com/MLcourse/pw-6.html#the-iris-dataset"><i class="fa fa-check"></i>The Iris Dataset</a></li>
<li class="chapter" data-level="" data-path="pw-6.html"><a href="https://www.mghassany.com/MLcourse/pw-6.html#loading-data-1"><i class="fa fa-check"></i>Loading Data</a></li>
<li class="chapter" data-level="" data-path="pw-6.html"><a href="https://www.mghassany.com/MLcourse/pw-6.html#exploratory-analysis"><i class="fa fa-check"></i>Exploratory analysis</a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-6.html#pca-using-princomp">PCA using <code>princomp()</code></a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-6.html#deeper-pca-using-factoextra-package">Deeper PCA using <code>factoextra</code> package</a></li>
<li class="chapter" data-level="" data-path="pw-6.html"><a href="https://www.mghassany.com/MLcourse/pw-6.html#step-by-step-pca"><i class="fa fa-check"></i>Step-by-step PCA</a></li>
</ul></li>
<li class="part"><span><b>III Unsupervised Learning</b></span></li>
<li class="chapter" data-level="7" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html"><i class="fa fa-check"></i><b>7</b> Kmeans &amp; Hierarchical Clustering</a><ul style="display: none;">
<li class="chapter" data-level="7.1" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#unsupervised-learning-1"><i class="fa fa-check"></i><b>7.1</b> Unsupervised Learning</a></li>
<li class="chapter" data-level="7.2" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#clustering"><i class="fa fa-check"></i><b>7.2</b> Clustering</a></li>
<li class="chapter" data-level="7.3" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#introduction-4"><i class="fa fa-check"></i><b>7.3</b> Introduction</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#hard-clustering"><i class="fa fa-check"></i>Hard clustering</a></li>
<li class="chapter" data-level="" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#fuzzy-clustering"><i class="fa fa-check"></i>Fuzzy clustering</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#k-means"><i class="fa fa-check"></i><b>7.4</b> <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-13-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-67" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-68" class="mjx-mrow"><span id="MJXc-Node-69" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">k</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-13">k</script></span>-Means</a><ul style="display: none;">
<li class="chapter" data-level="7.4.1" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#k-means-in"><i class="fa fa-check"></i><b>7.4.1</b> <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-14-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-70" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-71" class="mjx-mrow"><span id="MJXc-Node-72" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">k</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-14">k</script></span>-means in <svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 581 512"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg></a></li>
<li class="chapter" data-level="7.4.2" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#cluster-validity-choosing-the-number-of-clusters"><i class="fa fa-check"></i><b>7.4.2</b> Cluster Validity, Choosing the Number of Clusters</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#hierarchical-clustering"><i class="fa fa-check"></i><b>7.5</b> Hierarchical Clustering</a><ul style="display: none;">
<li class="chapter" data-level="7.5.1" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#dendrogram"><i class="fa fa-check"></i><b>7.5.1</b> Dendrogram</a></li>
<li class="chapter" data-level="7.5.2" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#the-hierarchical-clustering-algorithm"><i class="fa fa-check"></i><b>7.5.2</b> The Hierarchical Clustering Algorithm</a></li>
<li class="chapter" data-level="7.5.3" data-path="kmeans-hierarchical-clustering.html"><a href="https://www.mghassany.com/MLcourse/kmeans-hierarchical-clustering.html#hierarchical-clustering-in"><i class="fa fa-check"></i><b>7.5.3</b> Hierarchical clustering in <svg style="height:0.8em;top:.04em;position:relative;fill:steelblue;" viewBox="0 0 581 512"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html"><i class="fa fa-check"></i>PW 7</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#reporting-1"><i class="fa fa-check"></i>Reporting</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#markdown"><i class="fa fa-check"></i>Markdown</a></li>
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#r-markdown"><i class="fa fa-check"></i>R Markdown</a></li>
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#the-report-to-be-submitted"><i class="fa fa-check"></i>The report to be submitted</a></li>
</ul></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#k-means-clustering"><span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-15-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-73" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-74" class="mjx-mrow"><span id="MJXc-Node-75" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">k</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-15">k</script></span>-means clustering</a><ul style="display: none;">
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#pointscards"><code>pointsCards</code></a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#ligue-1"><code>Ligue 1</code></a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#pca"><code>PCA</code></a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#implementing-k-means"><code>Implementing k-means</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#hierarchical-clustering-1"><i class="fa fa-check"></i>Hierarchical clustering</a><ul style="display: none;">
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#distances-dist">Distances <code>dist()</code></a></li>
<li><a href="https://www.mghassany.com/MLcourse/pw-7.html#dendrogram-hclust">Dendrogram <code>hclust()</code></a></li>
<li class="chapter" data-level="" data-path="pw-7.html"><a href="https://www.mghassany.com/MLcourse/pw-7.html#hierarchical-clustering-on-iris-dataset"><i class="fa fa-check"></i>Hierarchical clustering on Iris dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="gaussian-mixture-models-em.html"><a href="https://www.mghassany.com/MLcourse/gaussian-mixture-models-em.html"><i class="fa fa-check"></i><b>8</b> Gaussian Mixture Models &amp; EM</a><ul style="display: none;">
<li class="chapter" data-level="8.1" data-path="gaussian-mixture-models-em.html"><a href="https://www.mghassany.com/MLcourse/gaussian-mixture-models-em.html#the-gaussian-distribution"><i class="fa fa-check"></i><b>8.1</b> The Gaussian distribution</a></li>
<li class="chapter" data-level="8.2" data-path="gaussian-mixture-models-em.html"><a href="https://www.mghassany.com/MLcourse/gaussian-mixture-models-em.html#mixture-of-gaussians"><i class="fa fa-check"></i><b>8.2</b> Mixture of Gaussians</a></li>
<li class="chapter" data-level="8.3" data-path="gaussian-mixture-models-em.html"><a href="https://www.mghassany.com/MLcourse/gaussian-mixture-models-em.html#em-for-gaussian-mixtures"><i class="fa fa-check"></i><b>8.3</b> EM for Gaussian Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pw-8.html"><a href="https://www.mghassany.com/MLcourse/pw-8.html"><i class="fa fa-check"></i>PW 8</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="pw-8.html"><a href="https://www.mghassany.com/MLcourse/pw-8.html#report-template"><i class="fa fa-check"></i>Report template</a></li>
<li class="chapter" data-level="8.4" data-path="pw-8.html"><a href="https://www.mghassany.com/MLcourse/pw-8.html#em-using-mclust"><i class="fa fa-check"></i><b>8.4</b> EM using <code>mclust</code></a><ul style="display: none;">
<li><a href="https://www.mghassany.com/MLcourse/pw-8.html#gmm-vs-k-means">GMM vs <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-16-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-76" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-77" class="mjx-mrow"><span id="MJXc-Node-78" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.491em; padding-bottom: 0.308em;">k</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>k</mi></math></span></span><script type="math/tex" id="MathJax-Element-16">k</script></span>-means</a></li>
<li class="chapter" data-level="" data-path="pw-8.html"><a href="https://www.mghassany.com/MLcourse/pw-8.html#em-on-1d"><i class="fa fa-check"></i>EM on 1D</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="pw-8.html"><a href="https://www.mghassany.com/MLcourse/pw-8.html#em-from-scratch"><i class="fa fa-check"></i><b>8.5</b> EM from scratch</a></li>
</ul></li>
<li class="part"><span><b>Hackathon</b></span></li>
<li class="chapter" data-level="" data-path="hackathon.html"><a href="https://www.mghassany.com/MLcourse/hackathon.html"><i class="fa fa-check"></i>Hackathon</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-introRStudio.html"><a href="https://www.mghassany.com/MLcourse/app-introRStudio.html"><i class="fa fa-check"></i><b>A</b> Introduction to <code>RStudio</code></a></li>
<li class="chapter" data-level="B" data-path="app-ht.html"><a href="https://www.mghassany.com/MLcourse/app-ht.html"><i class="fa fa-check"></i><b>B</b> Review on hypothesis testing</a></li>
<li class="chapter" data-level="C" data-path="use-qual.html"><a href="https://www.mghassany.com/MLcourse/use-qual.html"><i class="fa fa-check"></i><b>C</b> Use of qualitative predictors</a></li>
<li class="chapter" data-level="D" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html"><i class="fa fa-check"></i><b>D</b> Model Selection</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#linear-model-selection-and-best-subset-selection"><i class="fa fa-check"></i>Linear Model Selection and Best Subset Selection</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#forward-stepwise-selection"><i class="fa fa-check"></i>Forward Stepwise Selection</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#backward-stepwise-selection"><i class="fa fa-check"></i>Backward Stepwise Selection</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#estimating-test-error-using-mallows-cp-aic-bic-adjusted-r-squared"><i class="fa fa-check"></i>Estimating Test Error Using Mallows Cp, AIC, BIC, Adjusted R-squared</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#estimating-test-error-using-cross-validation"><i class="fa fa-check"></i>Estimating Test Error Using Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#examples"><i class="fa fa-check"></i>Examples</a><ul style="display: none;">
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#best-subset-selection"><i class="fa fa-check"></i>Best Subset Selection</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#forward-stepwise-selection-and-model-selection-using-validation-set"><i class="fa fa-check"></i>Forward Stepwise Selection and Model Selection Using Validation Set</a></li>
<li class="chapter" data-level="" data-path="model-selection.html"><a href="https://www.mghassany.com/MLcourse/model-selection.html#model-selection-using-cross-validation"><i class="fa fa-check"></i>Model Selection Using Cross-Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="references-and-credits.html"><a href="https://www.mghassany.com/MLcourse/references-and-credits.html"><i class="fa fa-check"></i><b>E</b> References and Credits</a></li>
<li class="chapter" data-level="F" data-path="other-references.html"><a href="https://www.mghassany.com/MLcourse/other-references.html"><i class="fa fa-check"></i><b>F</b> Other References</a></li>
<li class="chapter" data-level="" data-path="main-references-credits.html"><a href="https://www.mghassany.com/MLcourse/main-references-credits.html"><i class="fa fa-check"></i>Main References &amp; Credits</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body fixed">
      <div class="body-inner">
        <div class="book-header fixed" role="navigation" style="background-color: rgb(255, 255, 255);">
          <a class="btn pull-left js-toolbar-action" aria-label="Toggle Sidebar" title="Toggle Sidebar" href="https://www.mghassany.com/MLcourse/pw-5.html#"><i class="fa fa-align-justify"></i></a><a class="btn pull-left js-toolbar-action" aria-label="Search" title="Search" href="https://www.mghassany.com/MLcourse/pw-5.html#"><i class="fa fa-search"></i></a><div class="dropdown pull-left font-settings js-toolbar-action"><a class="btn toggle-dropdown" aria-label="Font Settings" title="Font Settings" href="https://www.mghassany.com/MLcourse/pw-5.html#"><i class="fa fa-font"></i></a><div class="dropdown-menu dropdown-right"><div class="dropdown-caret"><span class="caret-outer"></span><span class="caret-inner"></span></div><div class="buttons"><button class="button size-2 font-reduce">A</button><button class="button size-2 font-enlarge">A</button></div><div class="buttons"><button class="button size-2 ">Serif</button><button class="button size-2 ">Sans</button></div><div class="buttons"><button class="button size-3 ">White</button><button class="button size-3 ">Sepia</button><button class="button size-3 ">Night</button></div></div></div><a class="btn pull-left js-toolbar-action" aria-label="Information about the toolbar" title="Information about the toolbar" href="https://www.mghassany.com/MLcourse/pw-5.html#"><i class="fa fa-info"></i></a><h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="https://www.mghassany.com/MLcourse/">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class="rmdreview">
    If you find any typos, errors, or places where the text may be improved, please let me know by adding an annotation using <a href="https://hypothes.is/">hypothes.is</a>. To add an annotation, <span style="background-color: #3297FD; color: white">select some text</span> and then click the
      <span class="svg-icon--inline"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" class="annotator-adder-actions__icon">
      <path fill="currentColor" fill-rule="nonzero" d="M15 0c.27 0 .505.099.703.297A.961.961 0 0116 1v15l-4-3H1a.974.974 0 01-.703-.29A.953.953 0 010 12V1C0 .719.096.482.29.29A.966.966 0 011 0h14zM7 3l-.469.063c-.312.041-.656.187-1.031.437-.375.25-.719.646-1.031 1.188C4.156 5.229 4 6 4 7l.002.063.006.062a.896.896 0 01.008.11l-.002.074-.006.066a1.447 1.447 0 00.43 1.188C4.729 8.854 5.082 9 5.5 9c.417 0 .77-.146 1.063-.438C6.854 8.271 7 7.918 7 7.5c0-.417-.146-.77-.438-1.063A1.447 1.447 0 005.5 6c-.073 0-.146.005-.219.016-.073.01-.14.026-.203.046.177-1.03.542-1.632 1.094-1.804L7 4V3zm5 0l-.469.063c-.312.041-.656.187-1.031.437-.375.25-.719.646-1.031 1.188C9.156 5.229 9 6 9 7l.002.063.006.062a.896.896 0 01.008.11l-.002.074-.006.066a1.447 1.447 0 00.43 1.188c.291.291.645.437 1.062.437.417 0 .77-.146 1.063-.438.291-.291.437-.645.437-1.062 0-.417-.146-.77-.438-1.063A1.447 1.447 0 0010.5 6c-.073 0-.146.005-.219.016-.073.01-.14.026-.203.046.177-1.03.542-1.632 1.094-1.804L12 4V3z"></path>
    </svg>
    </span>
      on the pop-up menu.
      To see the annotations of others, click the
      <span class="svg-icon--inline"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" class=""><g fill-rule="evenodd"><rect fill="none" stroke="none" x="0" y="0" width="16" height="16"></rect><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 12L6 8l4-4"></path></g></svg>
</span>
      in the upper right-hand corner of the page.
    <p></p>
</div>
<div id="pw-5" class="section level1 unnumbered">
<h1 class="hasAnchor">PW 5<a href="https://www.mghassany.com/MLcourse/pw-5.html#pw-5" class="anchor-section"></a></h1>
<p>In this practical work, we will build some decision trees for both <em>regression</em> and <em>classification</em> problems. Note that there are many packages to do this in <i class="fab  fa-r-project " style="color:steelblue;"></i> . The <code>tree</code> package is the basic package to do so, while the <code>rpart</code><a href="https://www.mghassany.com/MLcourse/pw-5.html#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> package seems more widely suggested and provides better plotting features. So we will use the <code>rpart</code> package.</p>
<div class="rmdcaution">
<p>It is recommended for correct and better using of <i class="fab  fa-r-project " style="color:steelblue;"></i> functions that you consult their documentations. Every <i class="fab  fa-r-project " style="color:steelblue;"></i> function is well documented indeed. You can do so by writing <code>?function_name</code> or <code>help(function_name)</code>in the console.</p>
<p>Especially for functions with multiple use, for example, <code>glm()</code> is a function that fits generalizes linear models, one of them is logistic regression when <code>type = "binomial"</code>.</p>
<p>Another example, is the function <code>predict()</code>, that is a generic function for predictions from the results of various model fitting functions. Its first argument is a <i class="fab  fa-r-project " style="color:steelblue;"></i> object, a model, and the rest of the arguments depends on the nature of the object. If you want to consult the documentation about using <code>predict()</code> for a tree built with <code>rpart()</code>, do <code>?predict.rpart</code> or <code>help(predict.rpart)</code></p>
</div>
<div class="rmdtip">
<p>If you want to run a function from a certain package without loading the package, you can write <code>package::function()</code>. For example <code>MASS::lda()</code> or <code>rpart::rpart()</code>. It is also helpful to remember the name of the package in which the function is defined.</p>
</div>
<div id="regression-trees" class="section level2 unnumbered">
<h2 class="hasAnchor">Regression Trees<a href="https://www.mghassany.com/MLcourse/pw-5.html#regression-trees" class="anchor-section"></a></h2>
<div id="single-tree" class="section level3 unnumbered">
<h3 class="hasAnchor">Single tree<a href="https://www.mghassany.com/MLcourse/pw-5.html#single-tree" class="anchor-section"></a></h3>
<p>To demonstrate regression trees, we will use the <code>Boston</code> dataset that we used during the first two practical works, from the <code>MASS</code> package. Recall that <code>medv</code> is the response.</p>
<p><strong>1</strong>. Load the Boston dataset from <code>MASS</code> package. Split the dataset randomly in half.</p>
<div class="sourceCode" id="cb45"><button type="button" class="copy-to-clipboard-button" title="Copy to clipboard" aria-label="Copy to clipboard"><i class="fa fa-copy"></i></button><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" title="1"><span class="kw">library</span>(MASS)</a>
<a class="sourceLine" id="cb45-2" title="2"><span class="kw">library</span>(caTools)</a>
<a class="sourceLine" id="cb45-3" title="3"><span class="kw">set.seed</span>(<span class="dv">18</span>)</a>
<a class="sourceLine" id="cb45-4" title="4">Boston_idx =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(Boston), <span class="kw">nrow</span>(Boston) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) </a>
<a class="sourceLine" id="cb45-5" title="5"><span class="co"># You don't know what we just did?</span></a>
<a class="sourceLine" id="cb45-6" title="6"><span class="co"># open the documentation of the function sample by </span></a>
<a class="sourceLine" id="cb45-7" title="7"><span class="co"># writing ?sample in the R console.</span></a>
<a class="sourceLine" id="cb45-8" title="8"><span class="co"># Note that this is one of the ways to split it randomly and it is not necessary the best.</span></a>
<a class="sourceLine" id="cb45-9" title="9">Boston_train =<span class="st"> </span>Boston[Boston_idx,]</a>
<a class="sourceLine" id="cb45-10" title="10">Boston_test  =<span class="st"> </span>Boston[<span class="op">-</span>Boston_idx,]</a></code></pre></div>
<p><strong>2</strong>. Fit a regression tree to the training data using the <code>rpart()</code> function from the <code>rpart</code> package. Name the tree <code>Boston_tree</code>.</p>
<p><strong>3</strong>. Plot the obtained tree using the following code.</p>
<div class="sourceCode" id="cb46"><button type="button" class="copy-to-clipboard-button" title="Copy to clipboard" aria-label="Copy to clipboard"><i class="fa fa-copy"></i></button><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="kw">plot</span>(Boston_tree)</a>
<a class="sourceLine" id="cb46-2" title="2"><span class="kw">text</span>(Boston_tree, <span class="dt">pretty =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb46-3" title="3"><span class="kw">title</span>(<span class="dt">main =</span> <span class="st">"Regression Tree"</span>)</a></code></pre></div>
<p><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-137-1.png" width="70%" style="display: block; margin: auto;"></p>
<p><strong>4</strong>. A better plot can be obtained using the <code>rpart.plot</code><a href="https://www.mghassany.com/MLcourse/pw-5.html#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> package. Re-plot the tree using it. You can use the <code>rpart.plot()</code> function which by default, when the output is continuous, each node shows: the predicted value, and the percentage of observations in the node. You can also use the <code>prp()</code> function.</p>
<p><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-138-1.png" width="50%" style="display: block; margin: auto;"><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-138-2.png" width="50%" style="display: block; margin: auto;"></p>
<p><strong>5</strong>. Print the obtained tree and print its summary. Between the things that you can see in the summary, the CP (complexity parameter) table and the importance of each variable in the model. Print the CP table using the <code>printcp()</code> function to see the cross validation results. Plot a comparison figure using the <code>plotcp()</code> function.</p>
<p>You will notice the obtained tree is <strong>pruned</strong>. This is because <code>rpart</code> prunes the tree by default by performing 10-fold cross-validation.</p>
<div class="rmdtip">
<p><code>rpart</code> keeps track of something called the complexity of a tree. The complexity measure is a combination of the size of a tree and the ability of the tree to separate the classes of the target variable. If the next best split in growing a tree does not reduce the trees overall complexity by a certain amount, <code>rpart</code> will terminate the growing process. This amount is specified by the complexity parameter, <code>cp</code>, in the call to <code>rpart()</code>. Setting <code>cp</code> to a negative amount (like -1) ensures that the tree will be fully grown. You can try it and then plot the tree.</p>
<p>Notice that the default <code>cp</code> value may over prune the tree (the default is the one with the lowest <code>xerror</code>). As a rule of thumb, its best to prune a decision tree using the <code>cp</code> of smallest tree that is within one standard deviation of the tree with the smallest <code>xerror</code>. In the example above (see the CP table and the figure obtained with <code>plotcp()</code>), the best <code>xerror</code> is 0.30517 with standard deviation 0.056180. So, we want the smallest tree with <code>xerror</code> less than 0.30517 + 0.05618 = 0.361. This is the tree with <code>cp = 0.025293</code>, so well want to prune our tree with a <code>cp</code> slightly greater than <code>0.025293</code>.</p>
</div>
<p>Next we will compare this regression tree to a linear model and will use RMSE as our metric. RMSE is the <strong>R</strong>oot <strong>M</strong>ean <strong>S</strong>quare <strong>E</strong>rror, which is the square root of the MSE.</p>
<p><strong>6</strong>. Write a <i class="fab  fa-r-project " style="color:steelblue;"></i> function that returns the RMSE of two vectors.</p>
<p><strong>7</strong>. Use the function <code>predict()</code> to predict the response on the test set. Then calculate the RMSE obtained with tree model.</p>
<p><strong>8</strong>. Fit a linear regression model on the training set. Then predict the response on the test set using the linear model. Calculate the RMSE and compare the performance of the tree and the linear regression model.</p>
<div class="rmdinsight">
<p>Here the most obvious linear regression beats the tree! Well improve on this tree by considering ensembles of trees.</p>
</div>
<p>You can visually compare the performance of both models by plotting the Actual (reality) response values against the predicted values. The model with closer points are to the diagonal (<code>y=x</code>) line is the better one. You can try to reproduce the figure below.</p>
<p><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-144-1.png" width="50%" style="display: block; margin: auto;"><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-144-2.png" width="50%" style="display: block; margin: auto;"></p>
<p>By aggregating many decision trees, using methods like <em>bagging</em>,
<em>random forests</em>, and <em>boosting</em>, the predictive performance of trees can be
substantially improved. We will now use these concepts, called <em>ensemble methods</em>.</p>
</div>
<div id="bagging" class="section level3 unnumbered">
<h3 class="hasAnchor">Bagging<a href="https://www.mghassany.com/MLcourse/pw-5.html#bagging" class="anchor-section"></a></h3>
<p>Bagging, or <em>Bootstrap aggregation</em>, is a general-purpose procedure for reducing the variance of a statistical learning method, it is particularly useful and frequently used in the context of decision trees. The idea is to take many training sets from the population, build a separate prediction model using each training set, and average the resulting predictions. Generally we do not have access to multiple training sets. Instead, we can bootstrap, by taking repeated samples from the (single) training data set.</p>
<p>To apply bagging to regression
trees, we simply construct <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-17-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-79" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-80" class="mjx-mrow"><span id="MJXc-Node-81" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.483em; padding-bottom: 0.27em;">B</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></span></span><script type="math/tex" id="MathJax-Element-17">B</script></span> regression trees using B bootstrapped training
sets, and average the resulting predictions. These trees are grown deep,
and are not pruned. Hence each individual tree has high variance, but
low bias. Averaging these <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-18-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;B&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-82" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-83" class="mjx-mrow"><span id="MJXc-Node-84" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.483em; padding-bottom: 0.27em;">B</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>B</mi></math></span></span><script type="math/tex" id="MathJax-Element-18">B</script></span> trees reduces the variance.</p>
<p><strong>9</strong>. Fit a bagged model, using the <code>randomForest()</code> function from the <code>randomForest</code> package.</p>
<div class="rmdinsight">
<p>Bagging is actually a special case of a random forest where <code>mtry</code> is equal to <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-19-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-85" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-86" class="mjx-mrow"><span id="MJXc-Node-87" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.216em; padding-bottom: 0.483em;">p</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-19">p</script></span>, the number of predictors.</p>
</div>
<p><strong>10</strong>. Predict the response on the test set using the bagging model. Calculate the RMSE. Is the performance of the model better than linear regression or a simple tree?</p>
<p>Note that the Mean of squared residuals which is output by <code>randomForest()</code> is the <strong>Out of Bag</strong> estimate of the error. Here is its plot:</p>
<p><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-148-1.png" width="70%" style="display: block; margin: auto;"></p>
</div>
<div id="random-forests" class="section level3 unnumbered">
<h3 class="hasAnchor">Random Forests<a href="https://www.mghassany.com/MLcourse/pw-5.html#random-forests" class="anchor-section"></a></h3>
<p>Now try a random forest. For regression, on suggestion is to use <code>mtry</code> equal to <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-20-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mn&gt;3&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-88" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-89" class="mjx-mrow"><span id="MJXc-Node-90" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.216em; padding-bottom: 0.483em;">p</span></span><span id="MJXc-Node-91" class="mjx-texatom"><span id="MJXc-Node-92" class="mjx-mrow"><span id="MJXc-Node-93" class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.483em; padding-bottom: 0.59em;">/</span></span></span></span><span id="MJXc-Node-94" class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.377em; padding-bottom: 0.377em;">3</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>3</mn></math></span></span><script type="math/tex" id="MathJax-Element-20">p/3</script></span>.<a href="https://www.mghassany.com/MLcourse/pw-5.html#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
<p><strong>11</strong>. Fit a random forest on the training set and compare its performance with the previous models by calculating the predictions and the RMSE.</p>
<p><strong>12</strong>. Use the function <code>importance()</code> from the <code>randomForest</code> package to see the most important predictors in the obtained random forest model. What are the three most important predictors? Did you find the same results when you selected the best predictors for the linear regression model during session 2?</p>
<p><strong>13</strong>. Plot the importance of the predictors to the model using the <code>varImpPlot()</code> function.</p>
</div>
<div id="boosting-1" class="section level3 unnumbered">
<h3 class="hasAnchor">Boosting<a href="https://www.mghassany.com/MLcourse/pw-5.html#boosting-1" class="anchor-section"></a></h3>
<p>Last and not least, let us try a <em>boosted</em> model, which by default will produce a nice <strong>variable importance</strong> plot as well as plots of the marginal effects of the predictors. To do so, we will use the <code>gbm</code> package<a href="https://www.mghassany.com/MLcourse/pw-5.html#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>.</p>
<p><strong>14</strong>. Using the <code>gbm()</code> function like following, fit a boosted model on the training set. Then compare its performance with the previous models by calculating the predictions and the RMSE.</p>
<div class="sourceCode" id="cb47"><button type="button" class="copy-to-clipboard-button" title="Copy to clipboard" aria-label="Copy to clipboard"><i class="fa fa-copy"></i></button><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1"><span class="kw">library</span>(gbm)</a>
<a class="sourceLine" id="cb47-2" title="2">Boston_boost =<span class="st"> </span><span class="kw">gbm</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> Boston_train, <span class="dt">distribution =</span> <span class="st">"gaussian"</span>, </a>
<a class="sourceLine" id="cb47-3" title="3">                    <span class="dt">n.trees =</span> <span class="dv">5000</span>, <span class="dt">interaction.depth =</span> <span class="dv">4</span>, <span class="dt">shrinkage =</span> <span class="fl">0.01</span>)</a></code></pre></div>
<pre><code>#ans&gt; Using 5000 trees...</code></pre>
<p><strong>15</strong>. Show the summary of the boosted model. A figure of the variable importance will be shown.</p>
</div>
<div id="comparison-1" class="section level3 unnumbered">
<h3 class="hasAnchor">Comparison<a href="https://www.mghassany.com/MLcourse/pw-5.html#comparison-1" class="anchor-section"></a></h3>
<p><strong>16</strong>. Reproduce the following comparison: A table in which we show the obtained RMSE with each tested model, you can create a <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-21-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mn&gt;5&lt;/mn&gt;&lt;mo&gt;&amp;#x00D7;&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-95" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-96" class="mjx-mrow"><span id="MJXc-Node-97" class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.377em; padding-bottom: 0.377em;">5</span></span><span id="MJXc-Node-98" class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.216em; padding-bottom: 0.323em;"></span></span><span id="MJXc-Node-99" class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.377em; padding-bottom: 0.323em;">2</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>5</mn><mo></mo><mn>2</mn></math></span></span><script type="math/tex" id="MathJax-Element-21">5 \times 2</script></span> data.frame in which you put the names of the models and the corresponding RMSE. To visualize the data frame in the compiled html report you can use the <code>kable()</code> function from the <code>knitr</code> package. Or, compare the models by plotting the Actual (reality) response values against the predicted values.</p>
<p><img src="./PW 5 _ Machine Learning_files/unnamed-chunk-158-1.png" width="90%" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="classification-trees-1" class="section level2 unnumbered">
<h2 class="hasAnchor">Classification Trees<a href="https://www.mghassany.com/MLcourse/pw-5.html#classification-trees-1" class="anchor-section"></a></h2>
<p>A classification tree is very similar to a regression tree, except that the classification tree is used to predict a qualitative response rather than a quantitative one. Recall that for a regression tree, the predicted response for an observation is given by the mean response of the training observations that belong to the
same terminal node. In contrast, for a classification tree, we predict that
each observation belongs to the <strong><em>most commonly occurring class</em></strong> of training
observations in the region to which it belongs.</p>
<p>To construct classification trees, we will use the <strong>spam</strong><a href="https://www.mghassany.com/MLcourse/pw-5.html#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> dataset, available <a href="https://www.mghassany.com/MLcourse/datasets/spam.csv" target="_blank">here <svg style="height:0.8em;top:.04em;position:relative;fill:#cd0050;" viewBox="0 0 512 512"><path d="M464 32H48C21.49 32 0 53.49 0 80v352c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V80c0-26.51-21.49-48-48-48zM224 416H64v-96h160v96zm0-160H64v-96h160v96zm224 160H288v-96h160v96zm0-160H288v-96h160v96z"></path></svg></a>. A description of the dataset is given below.</p>
<div class="rmdexercise">
<p>For the rest of this PW, you must:</p>
<ul>
<li>Import the <code>spam</code> dataset and explore it. Be aware that it is preferable that the response column is of type factor.</li>
<li>Split the dataset into training and test sets (choose your own seed when using <code>set.seed()</code>).</li>
<li>Fit (using <code>rpart</code> and <code>gbm</code> packages):
<ul>
<li>A <strong>logistic</strong> regression model.</li>
<li>A simple classification tree.</li>
<li>Bagging, Random Forests<a href="https://www.mghassany.com/MLcourse/pw-5.html#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>, and Boosting models.</li>
</ul></li>
<li>For each model, predict the response on the test set and evaluate the performance of the model, using the <em>prediction accuracy</em> (create a function that returns the accuracy for two binary vectors).</li>
</ul>
</div>
<div id="the-spam-dataset" class="section level3 unnumbered">
<h3 class="hasAnchor">The Spam dataset<a href="https://www.mghassany.com/MLcourse/pw-5.html#the-spam-dataset" class="anchor-section"></a></h3>
<p>This dataset consists of information from 4601 email messages, in a study to try to predict whether the email was junk email, or
spam. For all 4601 email messages, the true outcome, spam or not, is available,
along with 57 predictors as described below:</p>
<ul>
<li>48 quantitative predictors: the <em>percentage</em> of words in the email that match a given word. Examples include <em>business</em>, <em>address</em>, <em>internet</em>; etc.</li>
<li>6 quantitative predictors: the percentage of characters in the email that match a given character. The characters are <code>;</code> , <code>(</code> , <code>[</code> , <code>!</code> , <code>$</code> and <code>#</code>.</li>
<li>The average length of uninterrupted sequences of capital letters: <code>crl.ave</code>.</li>
<li>The length of the longest uninterrupted sequence of capital letters: <code>crl.long</code>.</li>
<li>The sum of the length of uninterrupted sequences of capital letters: <code>crl.tot</code>.</li>
</ul>
<div class="rmdtip">
<p>Note that the spam dataset given here is already treated and ready to be explored. To achieve this stage, some steps are required to treat the raw data, like Tokenization, Stemming, and Lemmatization. In this dataset the most important words are already selected and other variables are added.
Curious students can read more about these steps. Two famous <i class="fab  fa-r-project " style="color:steelblue;"></i> packages for text mining are <a href="https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf" target="_blank">tm</a> and <a href="https://www.tidytextmining.com/index.html" target="_blank">tidytext</a>.</p>
</div>
</div>
<div id="extra-tuning" class="section level3 unnumbered">
<h3 class="hasAnchor">Extra: Tuning<a href="https://www.mghassany.com/MLcourse/pw-5.html#extra-tuning" class="anchor-section"></a></h3>
<p>So far in this PW, we fit bagging, boosting and random forest models, but did not <strong>tune</strong> any of them, we simply used certain, somewhat arbitrary, parameters. Actually, to make these models better the parameters should be tuned. The parameters include:</p>
<ul>
<li>Bagging: Actually just a subset of Random Forest with <code>mtry</code> = <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-22-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-100" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-101" class="mjx-mrow"><span id="MJXc-Node-102" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.216em; padding-bottom: 0.483em;">p</span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-22">p</script></span>.</li>
<li>Random Forest: <code>mtry</code></li>
<li>Boosting: <code>n.trees</code>, <code>interaction.depth</code>, <code>shrinkage</code>, <code>n.minobsinnode</code></li>
</ul>
<p>The <code>caret</code> package provides excellent functions to accomplish this. Note that with these tree-based ensemble methods there are two resampling solutions for tuning the model:</p>
<ul>
<li>Out of Bag</li>
<li>Cross-Validation</li>
</ul>
<p>Using Out of Bag samples is advantageous with these methods as compared to Cross-Validation since it removes the need to refit the model and is thus much more computationally efficient. Unfortunately OOB methods cannot be used with <code>gbm</code> models. See the <code>caret</code> documentation: <a href="https://cran.r-project.org/web/packages/caret/vignettes/caret.html" target="_blank">Short intro</a>, <a href="https://topepo.github.io/caret/index.html" target="_blank">Long intro</a> for details.</p>
<p class="text-right">

</p>

</div>
</div>
</div>



<div class="footnotes">
<hr>
<ol start="17">
<li id="fn17"><p><a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">An Introduction to Recursive Partitioning Using the <code>rpart</code> Routines</a> - Details of the <code>rpart</code> package.<a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref17" class="footnote-back"></a></p></li>
<li id="fn18"><p><a href="http://www.milbo.org/doc/prp.pdf"><code>rpart.plot</code> Package</a> - Detailed manual on plotting with <code>rpart</code> using the <code>rpart.plot</code> package.<a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref18" class="footnote-back"></a></p></li>
<li id="fn19"><p>For classification a suggestion is <code>mtry</code> = <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-23-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msqrt&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-103" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-104" class="mjx-mrow"><span id="MJXc-Node-105" class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.537em; padding-bottom: 0.537em;"></span></span><span class="mjx-box" style="padding-top: 0.145em; border-top: 1.4px solid;"><span id="MJXc-Node-106" class="mjx-mrow"><span id="MJXc-Node-107" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.216em; padding-bottom: 0.483em;">p</span></span></span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msqrt><mi>p</mi></msqrt></math></span></span><script type="math/tex" id="MathJax-Element-23">\sqrt{p}</script></span>.<a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref19" class="footnote-back"></a></p></li>
<li id="fn20"><p><a href="https://www.rdocumentation.org/packages/gbm/versions/2.1.8" target="_blank"><strong>g</strong>eneralized <strong>b</strong>oosted <strong>m</strong>odels</a> <i class="fab  fa-r-project " style="color:steelblue;"></i> package<a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref20" class="footnote-back"></a></p></li>
<li id="fn21"><p><a href="https://archive.ics.uci.edu/ml/datasets/Spambase" target="_blank">Source</a><a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref21" class="footnote-back"></a></p></li>
<li id="fn22"><p>For classification, the suggested <code>mtry</code> for a random forest is <span class="math inline"><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span id="MathJax-Element-24-Frame" class="mjx-chtml MathJax_CHTML" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;msqrt&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation" style="font-size: 117%; position: relative;"><span id="MJXc-Node-108" class="mjx-math" aria-hidden="true"><span id="MJXc-Node-109" class="mjx-mrow"><span id="MJXc-Node-110" class="mjx-msqrt"><span class="mjx-box" style="padding-top: 0.045em;"><span class="mjx-surd"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.537em; padding-bottom: 0.537em;"></span></span><span class="mjx-box" style="padding-top: 0.145em; border-top: 1.4px solid;"><span id="MJXc-Node-111" class="mjx-mrow"><span id="MJXc-Node-112" class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.216em; padding-bottom: 0.483em;">p</span></span></span></span></span></span></span></span><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msqrt><mi>p</mi></msqrt></math></span></span><script type="math/tex" id="MathJax-Element-24">\sqrt{p}</script></span>.<a href="https://www.mghassany.com/MLcourse/pw-5.html#fnref22" class="footnote-back"></a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="https://www.mghassany.com/MLcourse/decision-trees-random-forests.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="https://www.mghassany.com/MLcourse/principal-components-analysis.html" class="navigation navigation-next " aria-label="Next page" style="margin-right: 17px;"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="./PW 5 _ Machine Learning_files/app.min.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/lunr.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/clipboard.min.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/plugin-search.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/plugin-sharing.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/plugin-fontsettings.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/plugin-bookdown.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/jquery.highlight.js.download"></script>
<script src="./PW 5 _ Machine Learning_files/plugin-clipboard.js.download"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>



<div class="annotator-frame annotator-outer annotator-collapsed" style=""><div class="annotator-toolbar"><div><button class="annotator-toolbar__sidebar-toggle" aria-label="Annotation sidebar" aria-expanded="false" aria-pressed="false" title="Annotation sidebar" style="touch-action: pan-y; user-select: none; -webkit-user-drag: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0);"><span class="svg-icon"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" class=""><g fill-rule="evenodd"><rect fill="none" stroke="none" x="0" y="0" width="16" height="16"></rect><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 12L6 8l4-4"></path></g></svg>
</span></button><div class="annotator-toolbar-buttonbar"><button class="annotator-toolbar-button" aria-label="Show highlights" aria-pressed="true" title="Show highlights"><span class="svg-icon"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" class=""><g fill-rule="evenodd"><rect fill="none" stroke="none" x="0" y="0" width="16" height="16"></rect><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 13c3.866 0 7-2.239 7-5s-3.134-5-7-5-7 2.239-7 5 3.134 5 7 5zm0-4a1 1 0 1 0 0-2 1 1 0 0 0 0 2z"></path></g></svg>
</span></button><button class="annotator-toolbar-button" aria-label="New page note" aria-pressed="false" title="New page note"><span class="svg-icon"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" class=""><g fill-rule="evenodd"><rect fill="none" stroke="none" x="0" y="0" width="16" height="16"></rect><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 15h6l8-6V1H1v14zm6-1V9h7"></path></g></svg>
</span></button></div></div></div><div class="annotator-bucket-bar"></div><iframe allowfullscreen="" src="./PW 5 _ Machine Learning_files/app.html" title="Hypothesis annotation viewer" class="h-sidebar-iframe"></iframe></div><hypothesis-adder style="display: block; position: absolute; top: 0px;"></hypothesis-adder></body></html>