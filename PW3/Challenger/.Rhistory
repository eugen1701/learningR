I=1/3*(1-exp(-3))
Iest=1/N99*sum(exp(-3*ech))
I=1/3*(1-exp(-3))
N99=(sqrt(ex_var)*Coef99*10^4)^2
N99=(sqrt(ex_var)*Coef99*10^4)^2
#Question 4
ech=runif(N99)
#Question 5
I=1/3*(1-exp(-3))
Iest=1/N99*sum(exp(-3*ech))
#Question 6
est_var=var(exp(-3*ech))
#Question 7
ex_var = 1/18*(1-5*exp(-6)+4*exp(-3))
#Question 8
Coef99 = qnorm(0.995)#quantile pour 99%
N99=(sqrt(ex_var)*Coef99*10^4)^2
#Question 9
ErrMonteCarlo=abs(I-Iapp)
plot(log(N),log(1/N*sum(exp(-3*ech))))
N=100000
for(i in N){
X=seq(0,1,length.out=i+1)#subdivision en N+1 points
X=X[1:length(X)-1]#méthode des rectangles gauches, on ne considère pas le dernier point
Iapprectangle[k]=mean(exp(-3*X))#formule de l'aire avec méthode des rectangles
k=k+1
}
Sn=1/N*sum(exp(-3*X))
Coef99 = qnorm(0.995)#quantile pour 99%
N99=(sqrt(ex_var)*Coef99*10^4)^2
Y=runif(N99,0,1)
Iest2=mean(exp(-3*Y))
print(Iest2)
print((I-Iest2)/I)
N=2^seq(1,20,0.2)
IappMonteCarlo=rep(0,length(N))
k=1
for(i in N){
a=0
b=1
X=runif(i)
IappMonteCarlo[k]=mean(exp(-3*X))
k=k+1
}
ErrMonteCarlo=abs(I-Iapp)
plot(log(N),log(IappMonteCarlo))
N=2^seq(1,20,0.2)
IappMonteCarlo=rep(0,length(N))
k=1
for(i in N){
a=0
b=1
X=runif(i)
IappMonteCarlo[k]=mean(exp(-3*X))
k=k+1
}
ErrMonteCarlo=abs(I-IappMonteCarlo)
plot(log(N),log(IappMonteCarlo))
N=2^seq(1,20,0.2)
IappMonteCarlo=rep(0,length(N))
k=1
for(i in N){
a=0
b=1
X=runif(i)
IappMonteCarlo[k]=mean(exp(-3*X))
k=k+1
}
ErrMonteCarlo=abs(I-IappMonteCarlo)
plot(log(N),log(ErrMonteCarlo))
ErrMonteCarlo.lm=lm(log(ErrMonteCarlo)~log(N))
print(ErrMonteCarlo.lm$coefficients)
help(rep)
N=10000
#Question 4
ech=runif(N)
#Question 5
I=1/3*(1-exp(-3))
Iest=1/N*sum(exp(-3*ech))#ou mean(exp(-3*ech))
#Question 6
est_var=var(exp(-3*ech))
#Question 7
ex_var = 1/18*(1-5*exp(-6)+4*exp(-3))
#Question 8
Coef99 = qnorm(0.995)#quantile pour 99%
N99=(sqrt(ex_var)*Coef99*10^4)^2
Y=runif(N99,0,1)
Iest2=mean(exp(-3*Y))#ou 1/N*sum(exp(-3*Y))
print(Iest2)
print((I-Iest2)/I)
#Question 9
N=2^seq(1,20,0.2)
IappMonteCarlo=c()
k=1
for(i in N){
a=0
b=1
X=runif(i)
IappMonteCarlo[k]=mean(exp(-3*X))#ou = 1/N*sum(exp(-3*X))
k=k+1
}
ErrMonteCarlo=abs(I-IappMonteCarlo)
#Méthode des moindres carrés
plot(log(N),log(ErrMonteCarlo))
ErrMonteCarlo.lm=lm(log(ErrMonteCarlo)~log(N))
print(ErrMonteCarlo.lm$coefficients)
#Question 11
N=100000
for(i in N){
X=seq(0,1,length.out=i+1)#subdivision en N+1 points
X=X[1:length(X)-1]#méthode des rectangles gauches, on ne considère pas le dernier point
Iapprectangle[k]=mean(exp(-3*X))#formule de l'aire avec méthode des rectangles
k=k+1
}
Sn=1/N*sum(exp(-3*X))
N=10000
#Question 4
ech=runif(N)
#Question 5
I=1/3*(1-exp(-3))
Iest=1/N*sum(exp(-3*ech))#ou mean(exp(-3*ech))
#Question 6
est_var=var(exp(-3*ech))
#Question 7
ex_var = 1/18*(1-5*exp(-6)+4*exp(-3))
#Question 8
Coef99 = qnorm(0.995)#quantile pour 99%
N99=(sqrt(ex_var)*Coef99*10^4)^2
Y=runif(N99,0,1)
Iest2=mean(exp(-3*Y))#ou 1/N*sum(exp(-3*Y))
print(Iest2)
print((I-Iest2)/I)
#Question 9
N=2^seq(1,20,0.2)
IappMonteCarlo=c()
k=1
for(i in N){
a=0
b=1
X=runif(i)
IappMonteCarlo[k]=mean(exp(-3*X))#ou = 1/N*sum(exp(-3*X))
k=k+1
}
ErrMonteCarlo=abs(I-IappMonteCarlo)
#Méthode des moindres carrés
plot(log(N),log(ErrMonteCarlo))
ErrMonteCarlo.lm=lm(log(ErrMonteCarlo)~log(N))
print(ErrMonteCarlo.lm$coefficients)
#Question 11
N=100000
Iapprectangle=c()
for(i in N){
X=seq(0,1,length.out=i+1)#subdivision en N+1 points
X=X[1:length(X)-1]#méthode des rectangles gauches, on ne considère pas le dernier point
Iapprectangle[k]=mean(exp(-3*X))#formule de l'aire avec méthode des rectangles
k=k+1
}
Sn=1/N*sum(exp(-3*X))
N=2^seq(1,20,0.2)
Iapprectangle=c()
k=1
for(i in N){
X=seq(0,1,length.out=i+1)#subdivision en N+1 points
X=X[1:length(X)-1]#méthode des rectangles gauches, on ne considère pas le dernier point
Iapprectangle[k]=mean(exp(-3*X))#formule de l'aire avec méthode des rectangles
k=k+1
}
Sn=1/N*sum(exp(-3*X))
help(points)
ErrRectangle=abs(Iapprectangle-I)
plot(log(N),log(ErrRectangle),col='blue')
points(log(N),log(ErrMonteCarlo),col='red')
plot(log(N),log(ErrRectangle),col='blue')
plot(log(N),log(ErrMonteCarlo),col='red',add=T)
plot(log(N),log(ErrRectangle),col='blue')
hold on
plot(log(N),log(ErrMonteCarlo),col='red')
plot(log(N),log(ErrRectangle),col='blue')
points(log(N),log(ErrMonteCarlo),col='red')
ErrRectangle.lm=lm(log(ErreurRectangle)~log(N))
print(ErrRectangle.lm$coefficients)
ErreurRectangle.lm=lm(log(ErreurRectangle)~log(N))
print(ErreurRectangle.lm$coefficients)
ErrRectangle.lm=lm(log(ErrRectangle)~log(N))
print(ErrRectangle.lm$coefficients)
N=10000
J=1/N*sum(ech*sin(1/ech))
help(integrate)
N=10000
f=function(x)x*sin(1/x)
J=1/N*sum(f(ech))
N=100000000
f=function(x)x*sin(1/x)
J=1/N*sum(f(ech))
N=100000000
f=function(x)x*sin(1/x)
ech=runif(N)
J=1/N*sum(f(ech))
N=100000000
f=function(x)x*sin(1/x)
ech=runif(N)
J=1/N*sum(f(ech))
N=10000000
f=function(x)x*sin(1/x)
ech=runif(N)
J=1/N*sum(f(ech))
integrate(f,0,1)
J=0.37853001712416210
integrate(f,0,1)
print((Jest1-J)/J)
N=10000000
f=function(x)x*sin(1/x)
ech=runif(N)
Jest1=1/N*sum(f(ech))
J=0.37853001712416210
integrate(f,0,1)
print((Jest1-J)/J)
N=10000000
f=function(x)x*sin(1/x)
ech=runif(N)
Jest1=1/N*sum(f(ech))
J=0.37853001712416210
integrate(f,0,1)
print((Jest1-J)/J)
N=10000000
f=function(x)x*sin(1/x)
ech=runif(N)
Jest1=1/N*sum(f(ech))
J=0.37853001712416210
integrate(f,0,1)
print((Jest1-J)/J)
N=10000000
f=function(x)x*sin(1/x)
ech=runif(N)
Jest1=1/N*sum(f(ech))
J=0.37853001712416210
integrate(f,0,1)
print((Jest1-J)/J)
X = runif(1000,0,4)
mean(sqrt(X)-0.5*X+2)
mean(4*sqrt(X))
X=runif(10000,0,4)
Y=4-X
var(sqrt(X))
2/9
X=runif(1000000,0,4)
var(sqrt(X))
Y=4-X
X=runif(100000000,0,4)
Y=4-X
var(sqrt(X)x)
var(sqrt(X))
X=runif(1000000,0,4)
Y=4-X
var(sqrt(X))
2/9
cov(sqrt(X),sqrt(Y))
mean(sqrt(X)-0.5*X+2)
16/3
var(sqrt(X)-0.5*X)
1/45
mean(2(sqrt(X)+sqrt(Y)))
mean(2(sqrt(X)+sqrt(4-X)))
mean(2*(sqrt(X)+sqrt(4-X)))
Y
mean(sqrt(x)-1/2*x)
X=runif(1000000,0,4)
mean(sqrt(X)-1/2*X)
mean(sqrt(X)-1/2*X+2)
S=0
n=10000
for (i in 1:n)
{
X=runif(1,-1,1)
S=S+2*log(X+4)
}
S/n
x = c(1,3,2,5)
x
x
ls()
rm(all)
clear all
rm(list=lsf.str())
ls
rm(list = ls(type="Values"))
rm(list = ls())
1:5
x = c(1,7,3,4)
x
y = 100:1
y
x[3] + y[4]
cos(x[3])+sin(x[2])*exp(-y[2])
x[3]=0
x
y[2]=-1
y
x[3] + y[4]
cos(x[3])+sin(x[2])*exp(-y[2])
z=y[x+1]
z
A = matrix(1:4,nrow=2,ncol=2)
A
B = matrix(1:4,nrow=2,ncol=2,byrow=TRUE)
B
rbind(1:3,4:6)
cbind(1:3,4:6)
A+1
A*B
A[2,1]
A[1,]
1[,2]
A[,2]
myDf = data.frame(var1=1:2,var2=3:4)
myDf
names(myDf = c("newname1","newname2"))
names(myDf) = c("newname1","newname2"))
names(myDf) = c("newname1","newname2")
myDf
myDf$newname1
myDf$myNewVariable = c(0,1)
mmyDf
myDf
myList = list(vec = vec, A=A,myDf=myDf)
vec=c(-4.12,-1,1.1,1,3,4)
vec
myList = list(vec = vec, A=A,myDf=myDf)
myList$vec
myList$A
myList$myDf
str(myList)
str(myDf)
names(myList)
x = rnorm(100)
y=rnorm(100)
plot(x,y)
plot(x,y,xlab="this is the x-axis")
plot(x,y,xlab="this is the x-axis",ylab = "this is the y-axis")
plot(x,y,xlab="this is the x-axis",ylab = "this is the y-axis",main = "Plot of X vs Y")
rnorm(n=10,mean=0,sd=1
)
set.seed(45678)
rnorm(n=10,mean=0,sd=1)
rnorm(n=10,mean=0,sd=1)
set.seed(45678)
rnorm(n=10,mean=0,sd=1)
x= seq(-4,4,l=100)
x
y = dnorm(x=x,mean=0,sd=1)
plot(x,y,type="l")
qf(p=0.90,df1=1,df2=5)
qf(p=0.95,df1=1,df2=5)
qf(p=0.99,df1=1,df2=5)
qf(p=0.90,df1=1,df2=5)
rpois(100,lambda=5)
dt(-4:4,df=1)
x=seq(-4,4)
y=dt(x=x,df=1)
plot(x,y)
plot(x,y,type="l")
plot(x,y)
x=seq(-4,4,l=100)
y=dt(x=x,df=1)
plot(x,y,type="l")
plot(x,y)
plot(x,y,type="l")
x1=seq(-4,4,l=100)
y1=dt(x=x1,df=1)
plot(x1,y1,type="l")
y2=dt(x=x1,df=5)
lines(x1,y2)
lines(x1,y2,col="green")
lines(x1,y4,col="blue")
x1=seq(-4,4,l=100)
y1=dt(x=x1,df=1)
plot(x1,y1,type="l")
y2=dt(x=x1,df=5)
y3=dt(x=x1,df=10)
y4=dt(x=x1,df=50)
y5=dt(x=x1,df=100)
lines(x1,y2,col="green")
lines(x1,y3,col="red")
lines(x1,y4,col="blue")
lines(x1,y5,col="yellow")
getwd()
Auto = read.table("Auto.data",header=T,na.strings="?")
Auto
dim(Auto)
nrow(Auto)
ncol(Auto)
Auto[1:4,]
names(Auto)
load("EU.RData"")
load("EU.RData")
mod = lm(formula = Seats2011 ~ Population2010, data = EU)
mod
names(mod)
mod$coefficients
mod$residuals
mod$fitted.values
sumMod = summary(mod)
sumMod
load("EU.RData")
myModel = lm(formula = CamCom2011 ~ Population2010, data=EU)
myModel$residuals
myModel$coefficients
summaryMyModel = summary(myModel)
summaryMyModel$sigma
install.packages("MASS")
library(MASS)
dim(Boston)
train = 1:400
test = -train
test
variables = which(names(Boston) ==c("lstat","medv"))
variables*
variables
training_data = Boston[train,variables]
testing_data = Boston[test,variables]
dim(training_data)
plot(training_data$lstat,training_data$medv)
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv")
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv",type="o",col="red",size=3)
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv",type="o",col="red")
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv",col="red")
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv",pch=2,col="red")
plot(training_data$lstat, training_data$medv,main = "Plot of lstat vs medv",xlab = "lstat",ylab = "medv",pch=2,col="red",cex=0.5)
plot(log(training_data$lstat),training_data$medv)
model = lm(medv ~ log(lstat),data=training_data)
model
summary(model)
#With all these informations we can assume that the slope is very different from 0
#Furthermore, the p-value is inferior to 0.05 (p-value = -25.9) which means that
#there is a significant relationship between the percentage of households with low socioeconomic income
#and the median house value.
#This relationship is negative. That is as the percantage of household with low socioeconomic income increases,
#the median house value decreases.
#Looking at  R2, we can deduce that  62.7% of the model variation is being explained by the predictor log(lstat).
names(model)
model$coefficients
confint(model,level=0.95)
#So, a  95% confidence interval for the slope of log(lstat) is (−13.13,−11.28).
plot(log(training_data$lstat),training_data$medv)
abline(model)
#So, a  95% confidence interval for the slope of log(lstat) is (−13.13,−11.28).
plot(log(training_data$lstat),training_data$medv,
xlab = "Log Transform of % of Houshold wit Low Socioeconomic Income",
ylab = "Median House Value",
col="red",
pch=20)
abline(model,col="blue",lwd=3)
abline(model,col="blue",lwd=10)
abline(model,col="blue",lwd=3)
lwd
#So, a  95% confidence interval for the slope of log(lstat) is (−13.13,−11.28).
plot(log(training_data$lstat),training_data$medv,
xlab = "Log Transform of % of Houshold wit Low Socioeconomic Income",
ylab = "Median House Value",
col="red",
pch=20)
abline(model,col="blue",lwd=3)
predict(model,data.frame(lstat=c(5)))
#Median value of the house with lstat = 5% is 32.1
predict(model, data.frame(lstat = c(5,10,15), interval="prediction"))
#Median values of houses with lstat = 5%, 10%, 15% are 32.1, 23.7, 18.7
y = testing_data$medv
y_hat = predict(model, data.frame(lstat=testing_data$lstat))
error = y-y_hat
error_squared=error^2
MSE=mean(error_squared)
MSE
plot(Boston$medv,Boston$age) #-0.37 : no linear relashionship between the two variables
#Question 1
library(MASS)
dim(Boston)
#Question 2
train = 1:400
test = -train
variables = which(names(Boston) ==c("lstat", "medv"))
training_set = Boston[train, variables]
testing_set = Boston[test, variables]
#Question 3
plot(Boston$medv,Boston$age) #-0.37 : no linear relashionship between the two variables
plot(Boston$age,Boston$medv) #-0.37 : no linear relashionship between the two variables
challenger = read.delim("challengers.txt")
getwd()
setwd("C:/Users/33610/Documents/ESILV/A4/Machine Learning/Challenger")
getwd()
challenger = read.delim("challengers.txt")
setwd("C:\Users\33610\Documents\ESILV\A4\Machine Learning\Challenger")
challenger = read.delim("challenger.txt")
View(challenger)
View(challenger)
View(challenger)
View(challenger)
scatterplot(nfails.field ~ temp, reg.line = lm, smooth = FALSE, spread = FALSE,
boxplots = FALSE, data = challenger)
require(car)
scatterplot(nfails.field ~ temp, reg.line = lm, smooth = FALSE, spread = FALSE,
boxplots = FALSE, data = challenger, subset = nfails.field > 0)
scatterplot(nfails.field ~ temp, reg.line = lm, smooth = FALSE, spread = FALSE,
boxplots = FALSE, data = challenger)
mod <- lm(nfails.field ~ temp, data = challenger)
par(mfrow = 1:2)
plot(mod, 1)
plot(mod, 1)
plot(mod, 2)
predict(nasa, newdata = data.frame(temp = -0.6), type = "response")
nasa <- glm(fail.field ~ temp, family = "binomial", data = challenger)
summary(nasa)
predict(nasa, newdata = data.frame(temp = -0.6), type = "response")
